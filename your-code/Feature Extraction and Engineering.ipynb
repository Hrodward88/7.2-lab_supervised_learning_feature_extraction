{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Engineering\n",
    "\n",
    "\n",
    "**Lesson Goals**\n",
    "\n",
    "In this lesson you are going to learn:\n",
    "\n",
    "    What feature selection is.\n",
    "    Why you need to select features.\n",
    "    How to select features.\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "From the Machine Learning perspective, a dataset represents a set of observations. Every observation in the dataset is represented by a row. Each row contains a number of columns or features. For example, in an application of financial credit assignment, every consumer applying for a loan is an observation in our dataset, and each observation is described by features such as age, marital status, amount of dependent persons, employment status, yearly income, etc. We would then generate a classification algorithm that would return a decision on whether we should approve a loan for each customer.\n",
    "Feature Selection\n",
    "\n",
    "In Machine Learning, feature engineering is the task of deciding how to represent an observation. There may be many features available, but all of them may not be necessarily useful. For instance, in our example credit application, the favorite refrigerator color of the consumer would not be relevant, and thus we would not include it in our list of features.\n",
    "\n",
    "In this lesson we will use the Kaggle Census dataset to demonstrate the data transformations.\n",
    "\n",
    "First, we will load the dataset using Pandas and look at the first five rows using the head function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusId</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>55221</td>\n",
       "      <td>26745</td>\n",
       "      <td>28476</td>\n",
       "      <td>2.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>26.5</td>\n",
       "      <td>23986</td>\n",
       "      <td>73.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>195121</td>\n",
       "      <td>95314</td>\n",
       "      <td>99807</td>\n",
       "      <td>4.5</td>\n",
       "      <td>83.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>26.4</td>\n",
       "      <td>85953</td>\n",
       "      <td>81.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>26932</td>\n",
       "      <td>14497</td>\n",
       "      <td>12435</td>\n",
       "      <td>4.6</td>\n",
       "      <td>46.2</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>8597</td>\n",
       "      <td>71.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>22604</td>\n",
       "      <td>12073</td>\n",
       "      <td>10531</td>\n",
       "      <td>2.2</td>\n",
       "      <td>74.5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>8294</td>\n",
       "      <td>76.8</td>\n",
       "      <td>16.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount</td>\n",
       "      <td>57710</td>\n",
       "      <td>28512</td>\n",
       "      <td>29198</td>\n",
       "      <td>8.6</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>22189</td>\n",
       "      <td>82.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CensusId    State   County  TotalPop    Men  Women  Hispanic  White  Black   \n",
       "0      1001  Alabama  Autauga     55221  26745  28476       2.6   75.8   18.5  \\\n",
       "1      1003  Alabama  Baldwin    195121  95314  99807       4.5   83.1    9.5   \n",
       "2      1005  Alabama  Barbour     26932  14497  12435       4.6   46.2   46.7   \n",
       "3      1007  Alabama     Bibb     22604  12073  10531       2.2   74.5   21.4   \n",
       "4      1009  Alabama   Blount     57710  28512  29198       8.6   87.9    1.5   \n",
       "\n",
       "   Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed   \n",
       "0     0.4  ...   0.5          1.3         1.8         26.5     23986  \\\n",
       "1     0.6  ...   1.0          1.4         3.9         26.4     85953   \n",
       "2     0.2  ...   1.8          1.5         1.6         24.1      8597   \n",
       "3     0.4  ...   0.6          1.5         0.7         28.8      8294   \n",
       "4     0.3  ...   0.9          0.4         2.3         34.9     22189   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         73.6        20.9           5.5         0.0           7.6  \n",
       "1         81.5        12.3           5.8         0.4           7.5  \n",
       "2         71.8        20.8           7.3         0.1          17.6  \n",
       "3         76.8        16.1           6.7         0.4           8.3  \n",
       "4         82.0        13.5           4.2         0.4           7.7  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census = pd.read_csv('../census.csv') \n",
    "census.head() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types\n",
    "\n",
    "Another issue that we will have to decide is the type of the attributes, it may be continuous, discrete, numeric, or categorical, and this decision may have further repercussions down the road.\n",
    "\n",
    "\n",
    "**Discrete Variables**\n",
    "\n",
    "A discrete variable is a variable that can only take on integer values. This type of variable is useful to describe features like age in years or number of children.\n",
    "\n",
    "\n",
    "**Continuous Variables**\n",
    "\n",
    "A continuous variable can take on any number within its defined range. Examples of continuous variables are an exact weight measurement of an object or a measurement of an exact distance between two points.\n",
    "\n",
    "\n",
    "**Categorical Variables**\n",
    "\n",
    "A categorical variable is a variable that can have a finite number of values within its defined range. Typically a categorical variable will have two or more values. The values may or may not be ordinal. An example of a ordinal categorical variable is a variable that describes the risk level of customers of an insurance company (for example, low, medium and high). An example of a non ordinal variable can be blood type or eye color. Either of these variables do not have an inherent ordering to them.\n",
    "\n",
    "Looking at the census dataset, we can see that TotalPop is a discrete variable since it is of type int64. PrivateWork and PublicWork are continuous variables as they are of type float64. State and County are categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CensusId             int64\n",
       "State               object\n",
       "County              object\n",
       "TotalPop             int64\n",
       "Men                  int64\n",
       "Women                int64\n",
       "Hispanic           float64\n",
       "White              float64\n",
       "Black              float64\n",
       "Native             float64\n",
       "Asian              float64\n",
       "Pacific            float64\n",
       "Citizen              int64\n",
       "Income             float64\n",
       "IncomeErr          float64\n",
       "IncomePerCap         int64\n",
       "IncomePerCapErr      int64\n",
       "Poverty            float64\n",
       "ChildPoverty       float64\n",
       "Professional       float64\n",
       "Service            float64\n",
       "Office             float64\n",
       "Construction       float64\n",
       "Production         float64\n",
       "Drive              float64\n",
       "Carpool            float64\n",
       "Transit            float64\n",
       "Walk               float64\n",
       "OtherTransp        float64\n",
       "WorkAtHome         float64\n",
       "MeanCommute        float64\n",
       "Employed             int64\n",
       "PrivateWork        float64\n",
       "PublicWork         float64\n",
       "SelfEmployed       float64\n",
       "FamilyWork         float64\n",
       "Unemployment       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming a Variable and Changing its Type\n",
    "\n",
    "There are cases where we may opt to transform a variable to change its type. Typically we take a discrete or continuous variable and transform it into a categorical variable by dividing the range into bins. For example, we might take a variable describing income and divide it into 3 bins - low income, medium income, and high income. Doing this comes with a cost of information loss. We simplify the variable but we have now lost information about each person's income.\n",
    "\n",
    "In the census dataset, we can convert the Income variable from continuous to categorical. Pandas offers us two functions to perform this task called cut and qcut. First we can look at the distribution of income using a histogram. This will give us a better idea of how many bins we want to have and how much of the data each bin should contain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "census.Income.hist();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the bulk of the data falls between approximately $30,000 and $70,000. If we created bins by dividing the range evenly into 3 bins, it would mean that there would be more people in the middle bin. Let's explore creating bins both based on the range of the data as well as based on the distribution of the data (in other words, based on percentiles of the population).\n",
    "\n",
    "We can pass to the cut function the number of bins and thus create bins using the range of the variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncomeRange\n",
       "(10386.046, 48150.333]    1984\n",
       "(48150.333, 85801.667]    1194\n",
       "(85801.667, 123453.0]       41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['IncomeRange'] = pd.cut(census.Income, 3) \n",
    "census.IncomeRange.value_counts() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also opt to create bins based on the distribution. In this case, we will look at the min, 33rd percentile, 66th percentile and the max. We can pass these percentiles to the qcut function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncomePercentile\n",
       "(10498.999, 40630.0]     1074\n",
       "(49736.832, 123453.0]    1073\n",
       "(40630.0, 49736.832]     1072\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['IncomePercentile'] = pd.qcut(census.Income, [0, 0.3333, 0.6666, 1]) \n",
    "census.IncomePercentile.value_counts()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection\n",
    "\n",
    "We have mentioned in previous lessons that machine learning seeks to balance predictive power and information loss. Creating more complex models can be computationally expensive. Therefore, it is our goal to create a simple model while sacrificing as little information as possible.\n",
    "\n",
    "\n",
    "**Correlated Features**\n",
    "\n",
    "A simple and important way to reduce variables is by removing correlated features. In performing feature selection, we want to avoid highly correlated features and dependent features. The reason is that adding one new highly correlated or dependent feature to the instance representation does not provide new information the Machine Learning can leverage, and it has the disadvantage of unnecessarily complicating the learning process and the resulting model. In our example, if we already have a yearly income feature, it may be redundant to include a fixed monthly income feature.\n",
    "\n",
    "In the census data, we would also like to avoid correlated features. One way to detect correlation between features is by computing the pairwise correlation of all numeric variables in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Alabama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m census\u001b[39m.\u001b[39;49mcorr() \n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10052\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m  10053\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m> 10054\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m  10056\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10057\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:1837\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1836\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1837\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1838\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1839\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/internals/managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1794\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1795\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Alabama'"
     ]
    }
   ],
   "source": [
    "census.corr() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Men and Women have a correlation of 0.999527. Therefore, we should drop one of the two to avoid redundant information.\n",
    "\n",
    "\n",
    "**Forward Greedy Feature Selection**\n",
    "\n",
    "Forward greedy feature selection is an algorithm that starts off with a single feature and keeps adding features to the model while there is still a significant improvement in a performance metric. We stop adding features once we no longer see a significant improvement. Our algorithm for forward feature selection can be described as the following:\n",
    "\n",
    "For every remaining feature f:\n",
    "\n",
    "    m is the model resulting from adding f to the best estimator with q features.\n",
    "    Test m.\n",
    "    Update b which is the best feature to add so far.\n",
    "\n",
    "The best performing q+1 features are the original q features plus feature b.\n",
    "\n",
    "This algorithm is a greedy algorithm. This means that we only make the optimal decision at each stage. We cannot go back and replace variables that we have already added. We can only move forward and add more variables or decide to stop.\n",
    "\n",
    "\n",
    "**Backward Elimination**\n",
    "\n",
    "This algorithm is also greedy and has the opposite strategy of forward selection. We start with all features and eliminate features one by one. Each time we select the variable for removal that has the least impact on model performance. Typically, we stop at a predetermined number of features.\n",
    "\n",
    "\n",
    "**Derived Features**\n",
    "\n",
    "A derived feature is a new feature that you create by combining two or more preexisting raw features. In our census example, we can create a derived feature for detecting counties that have a low median household income and unemployment higher than 7 percent.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighUnemploymentLowIncome\n",
       "0    2147\n",
       "1    1073\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['HighUnemploymentLowIncome'] = np.where((census.Unemployment > 0.07) & (census.IncomePercentile.cat.codes == 0), 1, 0) \n",
    "census.HighUnemploymentLowIncome.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that we converted the categorical column into coded data to allow easy comparison and then selected the lowest income group (where the code equals zero).\n",
    "\n",
    "How do we know whether Machine Learning will improve with our new derived feature? As mentioned previously on this chapter, Machine Learning is an experimental science, so you make the experiment of adding the new derived feature and compare the resulting quality metric with that of the original model.\n",
    "\n",
    "\n",
    "**Wrappers**\n",
    "\n",
    "A wrapper is a program that performs feature selection and provides the resulting feature set to the Machine Learning workflow. In our example credit application, if every applicant is described by a set of 20 features, but we suspect that not all of them are independent and informative, we may use a backward elimination wrapper, that will find the smallest best performing subset of features, let's assume that it has only 8 features, then the Machine Learning workflow would proceed from the sampling phase considering for the rest of the workflow only those 8 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
